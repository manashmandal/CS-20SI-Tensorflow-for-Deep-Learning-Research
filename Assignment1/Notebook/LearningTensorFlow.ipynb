{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression in TensorFlow\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "\n",
    "DATA_FILE = 'data/fire_theft.xls'\n",
    "\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override=\"utf-8\")\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "n_samples = sheet.nrows - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "w = tf.Variable(0.0, name='weights')\n",
    "b = tf.Variable(0.0, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yhat = X * w + b\n",
    "\n",
    "loss = tf.square(Y - Yhat, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 2069.6319333978354\n",
      "Epoch 1 : 2117.0123581953535\n",
      "Epoch 2 : 2092.302723001866\n",
      "Epoch 3 : 2068.5080461938464\n",
      "Epoch 4 : 2045.591184088162\n",
      "Epoch 5 : 2023.5146448101316\n",
      "Epoch 6 : 2002.2447619835536\n",
      "Epoch 7 : 1981.748338803649\n",
      "Epoch 8 : 1961.9944411260742\n",
      "Epoch 9 : 1942.9520116143283\n",
      "Epoch 10 : 1924.5930823644712\n",
      "Epoch 11 : 1906.8898800636332\n",
      "Epoch 12 : 1889.8164505837929\n",
      "Epoch 13 : 1873.347133841543\n",
      "Epoch 14 : 1857.4588400604468\n",
      "Epoch 15 : 1842.1278742424079\n",
      "Epoch 16 : 1827.332495119955\n",
      "Epoch 17 : 1813.0520579712022\n",
      "Epoch 18 : 1799.2660847636982\n",
      "Epoch 19 : 1785.9562132299961\n",
      "Epoch 20 : 1773.1024853109072\n",
      "Epoch 21 : 1760.689129482884\n",
      "Epoch 22 : 1748.6984157081515\n",
      "Epoch 23 : 1737.1138680398553\n",
      "Epoch 24 : 1725.920873066732\n",
      "Epoch 25 : 1715.1046249579008\n",
      "Epoch 26 : 1704.6500954309377\n",
      "Epoch 27 : 1694.5447134910141\n",
      "Epoch 28 : 1684.7746311347667\n",
      "Epoch 29 : 1675.328450968245\n",
      "Epoch 30 : 1666.1935385839038\n",
      "Epoch 31 : 1657.3584002084322\n",
      "Epoch 32 : 1648.8122658529207\n",
      "Epoch 33 : 1640.5440742547091\n",
      "Epoch 34 : 1632.5446836102221\n",
      "Epoch 35 : 1624.8043315147183\n",
      "Epoch 36 : 1617.3126799958602\n",
      "Epoch 37 : 1610.0622532456405\n",
      "Epoch 38 : 1603.0433557207386\n",
      "Epoch 39 : 1596.2479176106197\n",
      "Epoch 40 : 1589.668056331575\n",
      "Epoch 41 : 1583.2965242617897\n",
      "Epoch 42 : 1577.126371285745\n",
      "Epoch 43 : 1571.1501190634\n",
      "Epoch 44 : 1565.360979151513\n",
      "Epoch 45 : 1559.7523780798629\n",
      "Epoch 46 : 1554.3184364555138\n",
      "Epoch 47 : 1549.0529469620615\n",
      "Epoch 48 : 1543.950059985476\n",
      "Epoch 49 : 1539.0050282141283\n",
      "Epoch 50 : 1534.211797797609\n",
      "Epoch 51 : 1529.56534988646\n",
      "Epoch 52 : 1525.0607591186251\n",
      "Epoch 53 : 1520.6934648507852\n",
      "Epoch 54 : 1516.4585935090713\n",
      "Epoch 55 : 1512.3524023861364\n",
      "Epoch 56 : 1508.3695780125756\n",
      "Epoch 57 : 1504.5066588066873\n",
      "Epoch 58 : 1500.7606269073274\n",
      "Epoch 59 : 1497.126336559476\n",
      "Epoch 60 : 1493.600210891061\n",
      "Epoch 61 : 1490.1794991287668\n",
      "Epoch 62 : 1486.8605145300749\n",
      "Epoch 63 : 1483.639419928193\n",
      "Epoch 64 : 1480.5144186365596\n",
      "Epoch 65 : 1477.4811065652452\n",
      "Epoch 66 : 1474.5376660533782\n",
      "Epoch 67 : 1471.6799176652871\n",
      "Epoch 68 : 1468.9063155567717\n",
      "Epoch 69 : 1466.2136880280007\n",
      "Epoch 70 : 1463.5996563179153\n",
      "Epoch 71 : 1461.0614086978492\n",
      "Epoch 72 : 1458.597208841216\n",
      "Epoch 73 : 1456.2043069711044\n",
      "Epoch 74 : 1453.8807724802089\n",
      "Epoch 75 : 1451.6242183893032\n",
      "Epoch 76 : 1449.432753210976\n",
      "Epoch 77 : 1447.3042320180018\n",
      "Epoch 78 : 1445.237068621615\n",
      "Epoch 79 : 1443.228872676177\n",
      "Epoch 80 : 1441.2782130186733\n",
      "Epoch 81 : 1439.3831422174615\n",
      "Epoch 82 : 1437.542224922173\n",
      "Epoch 83 : 1435.7540219968096\n",
      "Epoch 84 : 1434.0160684508405\n",
      "Epoch 85 : 1432.3276573866606\n",
      "Epoch 86 : 1430.687153330871\n",
      "Epoch 87 : 1429.093016880254\n",
      "Epoch 88 : 1427.543719962062\n",
      "Epoch 89 : 1426.038033108981\n",
      "Epoch 90 : 1424.5748210840281\n",
      "Epoch 91 : 1423.1531702368743\n",
      "Epoch 92 : 1421.771026852585\n",
      "Epoch 93 : 1420.4274983895677\n",
      "Epoch 94 : 1419.121967994741\n",
      "Epoch 95 : 1417.85251878131\n",
      "Epoch 96 : 1416.618930517208\n",
      "Epoch 97 : 1415.4196022436731\n",
      "Epoch 98 : 1414.2534379121803\n",
      "Epoch 99 : 1413.1202843011845\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaa6492d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./my_graph/03/linear_reg', sess.graph)\n",
    "    \n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            _, l = sess.run([optimizer, loss], feed_dict={X : x, Y : y})\n",
    "            total_loss += l\n",
    "        print (\"Epoch {0} : {1}\".format(i, total_loss/n_samples))\n",
    "        \n",
    "    writer.close()\n",
    "    \n",
    "    w_value, b_value = sess.run([w, b])\n",
    "    \n",
    "X, y = data.T[0], data.T[1]\n",
    "plt.plot(X, y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w_value + b_value, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression for OCR\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /data/mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/data/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [batch_size, 784], name='features')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, 10] ,name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, 10]) ,name='bias')\n",
    "logits = tf.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits, Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0 : 1.2845190816270167\n",
      "Average loss epoch 1 : 0.7332399870965864\n",
      "Average loss epoch 2 : 0.6010412075719633\n",
      "Average loss epoch 3 : 0.5372319666794686\n",
      "Average loss epoch 4 : 0.4984478988708594\n",
      "Average loss epoch 5 : 0.4717013091890962\n",
      "Average loss epoch 6 : 0.4517468400907405\n",
      "Average loss epoch 7 : 0.43621481680647756\n",
      "Average loss epoch 8 : 0.42347004120444365\n",
      "Average loss epoch 9 : 0.413405565184591\n",
      "Total time: 4.618482828140259 seconds\n",
      "Optimization Finished\n",
      "Accuracy : 0.898\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./my_graph/03/logistic_reg', sess.graph)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            total_loss += loss_batch\n",
    "        \n",
    "        print(\"Average loss epoch {0} : {1}\".format(i, total_loss/n_batches))\n",
    "    print(\"Total time: {0} seconds\".format(time.time() - start_time))\n",
    "    print(\"Optimization Finished\")\n",
    "    \n",
    "    # Testing the model\n",
    "    n_batches = int(mnist.test.num_examples / batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y : Y_batch})\n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "    print(\"Accuracy : {0}\".format(total_correct_preds / mnist.test.num_examples))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630139\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple TensorFlow exercises\n",
    "You should thoroughly test your code\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "# 1a: Create two random 0-d tensors x and y of any distribution.\n",
    "# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n",
    "# Hint: look up tf.cond()\n",
    "# I do the first problem for you\n",
    "###############################################################################\n",
    "def print_var(variable, model):\n",
    "    with tf.Session() as session:\n",
    "        session.run(model)\n",
    "        print(session.run(variable))\n",
    "\n",
    "x = tf.random_uniform([])  # Empty array as shape creates a scalar.\n",
    "y = tf.random_uniform([])\n",
    "out = tf.cond(tf.less(x, y), lambda: tf.add(x, y), lambda: tf.sub(x, y))\n",
    "\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "print_var(y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1b: Create two 0-d tensors x and y randomly selected from -1 and 1.\n",
    "# Return x + y if x < y, x - y if x > y, 0 otherwise.\n",
    "# Hint: Look up tf.case().\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.random_uniform([], minval=-1, maxval=1)\n",
    "y = tf.random_uniform([], minval=-1, maxval=1)\n",
    "\n",
    "out = tf.case(\n",
    "              {\n",
    "               tf.less   (x, y): lambda: tf.add(x, y),\n",
    "               tf.greater(x, y): lambda: tf.sub(x, y)\n",
    "              },\n",
    "               default = lambda: tf.constant(0.0),\n",
    "               exclusive=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False]\n",
      " [ True False False]]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n",
    "# and y as a tensor of zeros with the same shape as x.\n",
    "# Return a boolean tensor that yields Trues if x equals y element-wise.\n",
    "# Hint: Look up tf.equal().\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.constant([[0, -2, -1], [0, 1, 2]])\n",
    "y = tf.zeros_like(x)\n",
    "\n",
    "out = tf.equal(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1d: Create the tensor x of value \n",
    "# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n",
    "# Get the indices of elements in x whose values are greater than 30.\n",
    "# Hint: Use tf.where().\n",
    "# Then extract elements whose values are greater than 30.\n",
    "# Hint: Use tf.gather().\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "                 30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "                 34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "                 27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "                 33.71149445,  28.59134293,  36.05556488,  28.66994858])\n",
    "\n",
    "out = tf.gather(x, indices=tf.where(x > 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n",
    "# 2, ..., 6\n",
    "# Hint: Use tf.range() and tf.diag().\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "out = tf.diag(tf.range(1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-932.514\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n",
    "# Calculate its determinant.\n",
    "# Hint: Look at tf.matrix_determinant().\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.random_normal(shape=(10, 10), stddev=1, mean=0.5)\n",
    "out = tf.matrix_determinant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  2  3 10  6  4  1  0  9]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n",
    "# Return the unique elements in x\n",
    "# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\n",
    "out, idx = tf.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n",
    "# as long as they are from the same distribution.\n",
    "# Use tf.less() and tf.select() to return:\n",
    "# - The mean squared error of (x - y) if the average of all elements in (x - y)\n",
    "#   is negative, or\n",
    "# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n",
    "# Hint: see the Huber loss function in the lecture slides 3.\n",
    "###############################################################################\n",
    "\n",
    "# YOUR CODE\n",
    "x = tf.random_normal(shape=(300,), stddev=1, mean=0.5)\n",
    "y = tf.random_normal(shape=(300,), stddev=1, mean=0.5)\n",
    "\n",
    "residual = tf.sub(x, y)\n",
    "mean = tf.div(tf.reduce_sum(residual), 300)\n",
    "\n",
    "condition = tf.less(mean, 0)\n",
    "\n",
    "small_res = 0.5 * tf.square(residual)\n",
    "large_res = residual - 0.5\n",
    "\n",
    "out = tf.select(condition, small_res, large_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84575582 -2.42943811 -0.62032926  0.64819503  2.08836842  1.38458061\n",
      " -2.98914242 -0.9232372   0.06528646 -1.38232887 -0.27166617  0.99233699\n",
      " -2.97479224 -2.51875997  2.21888709  2.60145783  1.8942008  -0.07591522\n",
      " -1.04239511 -1.48455191 -0.63246059 -0.08174157 -0.38979602 -1.406299\n",
      "  1.83908319 -1.12011027 -3.13526869 -2.33659148 -2.21863031 -0.90802813\n",
      "  1.02675605  1.07906985  2.35576749 -1.45940423 -1.52326393  2.06511855\n",
      "  1.67965984 -2.4510026  -2.32800293 -1.34461117 -1.26925492 -1.64591682\n",
      " -0.86407715 -0.61399287 -0.76828647  0.52986586  0.06576431  1.56482267\n",
      " -0.15203208 -0.83853161 -1.5099442   0.19050175 -2.39832211  0.09064162\n",
      "  0.98059952 -1.34732795 -0.74485409 -0.34591973 -1.59268761  1.37592578\n",
      "  0.57619607 -1.34699678 -1.66521156 -1.90893221  2.40681648 -0.41788614\n",
      "  0.63152206 -0.06358999 -1.05610383  1.65957189 -0.97401583 -1.88996649\n",
      "  0.41152835 -2.59478331 -0.92580533 -0.34965014 -1.4442358  -0.60184109\n",
      " -2.20360804  0.40562117  1.19791925 -1.7887342  -1.93626809 -0.34944597\n",
      " -3.71521997  0.90826607 -0.8909362   0.62645245 -0.46648908 -0.21210456\n",
      "  0.77289784 -3.4601326  -1.07595181 -1.44075644  0.43387514 -0.22921264\n",
      "  0.06770629  0.31892288  1.8983438  -0.10235468  0.03836191  0.73027432\n",
      "  0.16434622  1.70198822 -2.32172394 -0.31867296 -3.10482597  1.22352767\n",
      "  0.02649152 -3.22090626  1.16792536  3.48637152 -2.71926594 -0.49958467\n",
      " -0.77694929 -0.72684479 -1.02299201 -1.43524003 -2.7705493  -0.86654979\n",
      " -2.60861588 -0.50178671 -0.32751     1.14717567 -1.6114285   1.55653191\n",
      "  2.85868406  0.13151729 -1.70487821 -3.04112983  1.583462    0.08166003\n",
      " -0.84740484  4.09794092  1.80769324 -2.0281353  -0.5212791   0.16912138\n",
      " -1.26891768 -1.21689367 -3.24304199  0.71584594  0.66728973 -1.32792997\n",
      " -3.0179646  -1.3338685  -1.00129914  1.65709162 -1.52481282  0.19150138\n",
      "  0.50350904 -2.36841416  1.733706   -0.93262899 -2.81821871 -0.11207372\n",
      "  1.19097745 -0.01939821 -0.91715622 -1.11353707 -0.14217812 -0.62632459\n",
      " -0.50318086 -0.11666042 -0.01845998 -0.17767882 -2.4480443   4.41018963\n",
      " -0.50417328 -2.85403538 -0.67524725 -1.22289824  1.03388333 -0.56038284\n",
      "  1.58037877 -1.01220071  0.35415745 -1.39906824  3.36709833 -1.60684764\n",
      " -0.73852026  0.63520682 -1.27262235 -0.71852416 -1.76484132 -0.88542414\n",
      " -0.10753557  0.4040823   0.17199123  1.93488503 -0.4010627   0.80222607\n",
      " -0.76590794 -1.4126668  -0.93571472  0.45090336 -1.24392366 -0.80237842\n",
      " -2.2822957   0.84609914 -2.67623758 -0.27483165 -2.57053566  0.49875885\n",
      " -1.43875992 -1.5136441   0.68120492 -0.82530546 -0.93200421 -0.93375248\n",
      " -0.3168298  -0.20293975 -1.06114674  0.90785897  2.52154756 -1.95845234\n",
      "  0.09545249  0.48820037  1.48447061  1.02951813  2.90504169 -1.37172699\n",
      " -1.67542231 -1.58774114 -1.24156249  1.58134079  1.98544788 -0.84573346\n",
      " -1.918028   -1.35827684 -1.89654493 -0.07376838  0.47223824  0.22897863\n",
      " -0.20756236 -0.55116397 -1.52257168  0.63093042 -0.44971603 -1.34135735\n",
      " -2.28776026 -1.57212496 -0.19697261 -1.87657499  1.12087452 -0.09590507\n",
      " -2.65307093 -0.3195169  -1.89021838  0.04219306 -1.05885434  0.44651699\n",
      "  2.30009604 -2.77324414  2.18148899  0.50469446 -1.05737865 -1.63466787\n",
      "  0.28864568  0.98010993  0.65254271  1.50515771 -0.22548038 -2.01660442\n",
      " -0.75471389 -1.44763279 -1.2320689  -2.23195124  0.94884217  0.23277915\n",
      " -2.8558054   1.47340381 -0.78503788  1.10826302 -2.11032009  2.70969796\n",
      " -0.11703271 -1.98250997 -1.36718988  1.03727186 -1.35789824 -2.27724457\n",
      " -0.01499712 -2.36803985 -0.22403181 -3.22298336 -0.4477706   0.72723877\n",
      " -1.00255203  0.01991987  0.55591261 -0.40211558 -1.84583831 -1.57169867\n",
      " -0.16707212 -3.49001908 -0.58220232  0.16855156 -0.68969858  0.14020461]\n"
     ]
    }
   ],
   "source": [
    "print_var(out, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
